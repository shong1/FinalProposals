\documentclass[10pt]{article}
\usepackage{upgreek}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{stmaryrd}
\usepackage{cite}

%For Matrix horizontal line
\usepackage{booktabs}

\graphicspath{{/ReportImg}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg,.tif}

%opening
\title{3D Computer Vision \\ Final Project Proposal}
\author{Sungmin Hong}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}

The main theme of the final project is reconstructing 3D face from multiple sources. 
The first part of the project follows a framework suggested in the `Face reconstruction from the wild'~\cite{Kemel2011}.
The authors proposed the 3D face reconstruction method from large unstructured image collections, such as, images from google search or personal photo collections. 

\section{Algorithm Overview}

\noindent \textbf{Normalize Face Images \\} 

Since images from internet or personal collections are unstructured, we need to normalize each image to a canonical face, which is frontal view of a face.
In ~\cite{Kemel2011}, they used a fiducial-based approach to normalize faces. They first detect a face in the image by using the object detection method using the soft cascade method~\cite{Bourdev05}.
Fiducial points of a face, such as, corners of eyes, nostrils, tip of a nose, and etc. are extracted from the detected region by using the fiducial points detection method ~\cite{Everingham06}. 
The matlab codes for the face detection method is provided by the matlab package and the fiducial points detection method is provided in the matlab Computer Vision package. 

Let $q$ and $Q$ be the fiducials in 2D images and the 3D template shape. 
They assumed 2D points in each image are the weak perspective projection of 3D points on the template surface. 

\begin{equation}
    q = P_wQ = [ sR | t ]Q \\    
\label{eq1_1}
\end{equation}

To estimate $P_w$, they subtracted the centroid and calculate the pseudo-inverse of relative positions of 3D points.

\begin{equation}
 \tilde{q} = q - \bar{q} \qquad \tilde{Q} = Q - \bar{Q} \\
\end{equation}

\begin{equation}
 A = \tilde{q}\tilde{Q}^T( \tilde{Q}\tilde{Q}^T )^{-1} \\
\end{equation}

where $\bar{q}$ and $\bar{Q}$ are the mean of $q$ and $Q$. 
And the translation $t$ is defined as follows.

\begin{equation}
 t = \bar{q} - A\tilde{Q} \\
\end{equation}
e
$s$ and $R$ are recovered by estimating the singular values of $A$. 
Since the $R$ and $s$ is 3D translation and scaling, we add a row, which is the cross product of $A_1$ and $A_2$, and do the singular value decomposition.

\begin{equation}
  A' = \begin{bmatrix} A \\ \cmidrule(lr){1-1} A_1 \times A_2  \end{bmatrix} = U_AD_AV_A^T \\
\end{equation}

Then the rotation $R = U_AV_A^T$ and the two identical singular value becomes $s$.

\noindent \textbf{Initial Lighting and Shape Estimation \\}

Let $I_i$ be the $i$ th canonical face image of size $N$ and $M$ is the concatenated matrix of $K$ images.
Then $M$ is $N \times K$ matrix which contain all canonical face images with different lighting conditions.
The uncalibrated photometric stereo reconstruction method using the singular value decomposition method ~\cite{YuilleSEB99} 
take rank-4 approximation to get $M = LS$, where $n \times 4$ matrix $L = U_M \sqrt{D_M}$ and $4\times K$ matrix $S = \sqrt{D_M}V_M^T$.
$L$ and $S$ represent the light source directions and the surface properties, which are albedo and the surface normals, respectively.  \\

\noindent \textbf{Surface Refinement using Local Shape Estimation \\}

The surface $S$ reconstructed from the rank-4 approximation lose details by nature. 
To overcome the over smoothing problem, the local patches of an image are used to update $L$ and $S$.
Thus the distance at pixel $j$ is represented as follows, 

\begin{equation}
 d_j = |M_j - LS_j|^2 \\
\end{equation}

where $M_j$ is a $n \times 1$ vector representing the intensities of a pixel $j$ in all $K$ images. Then normalize the distance $d_j$ and select $k > 4$ images under the threshold. 
With $k$ iamges the surface structure at $j$ th pixel is estimated by minimizing

\begin{equation}
 \min_{S_j} ||M_{k \times 1} - L_{k \times 4}S_j || + S_j^TGS_j  \\
\end{equation}

where $G = diag( -1, 1, 1, 1 )$ for Tikhonov regularization. 

Then $S_j$ has a closed form solution, 

\begin{equation}
 S_j = (L_{k\times4}^TL_{k \times4} + G)^{-1}L^TM_{k\times1} \\
\end{equation}


\noindent \textbf{Ambiguity Recovery \\}

The rank-4 approximation of the surface properties and the lighting condition has $4\times4$ ambiguity since $M = LS$ can be  $M = LA^{-1}AS$ with an invertible $4 \times 4$ matrix $A$.
The ambiguity may lead to the surface to be non-integrable.
The ambiguity can be resolved by minimizing the energy between the template surface and the estimated surface property. 

\begin{equation}
 \min_{A}{ || S_t - AS ||^2 } \\
\end{equation}

where $A$ is $4 \times 4$ ambiguity and $S_t$ is the surface property of the template shape. 
Then $L$ is updated to $L' = LA^{-1}$ and $S' = AS$.


\noindent \textbf{Integration \\}

In theiry paper, they used the simple integration method, but it looks possible to use Chellappa's method.

\noindent \textbf{Update Template Surface \\}



\bibliography{Proposal}{}
\bibliographystyle{plain}
\end{document}
